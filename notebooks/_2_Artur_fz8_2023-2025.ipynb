{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cab32df8",
   "metadata": {},
   "source": [
    "# FZ8 Vehicle Registration Data Processing: Advanced Excel Parsing (2023-2025)\n",
    "\n",
    "This notebook processes modern German vehicle registration data from the FZ8 \n",
    "statistical series covering the period 2023-2025. The implementation features \n",
    "intelligent parsing of structured Excel sheets with configurable column mappings \n",
    "and comprehensive data cleaning procedures.\n",
    "\n",
    "## Workflow Overview\n",
    "1. Load configuration dictionary with sheet-specific parsing rules\n",
    "2. Extract data from Excel sheets using dynamic column mapping\n",
    "3. Apply comprehensive German character normalization and data validation\n",
    "4. Export standardized CSV files with UTF-8 encoding for downstream analysis\n",
    "\n",
    "## Key Variables\n",
    "- `CONFIG`: Dictionary containing sheet-specific parsing configurations\n",
    "- `DATA_DIR`: Source directory containing FZ8 Excel workbooks\n",
    "- `OUT_DIR`: Raw CSV output directory\n",
    "- `DST_DIR`: Processed data destination directory\n",
    "\n",
    "## Prerequisites\n",
    "- FZ8 Excel workbooks must be present in source directory\n",
    "- Sheets must follow the FZ8 naming convention (e.g., \"FZ 8.1\", \"FZ 8.2\")\n",
    "- Configuration dictionary must be properly defined for each sheet type"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d46a6c9",
   "metadata": {},
   "source": [
    "## Environment Setup\n",
    "\n",
    "Import essential libraries and configure directory paths for FZ8 data processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5b1daf56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Import essential libraries for FZ8 data processing ===\n",
    "import re                          # Regular expression pattern matching\n",
    "import warnings                    # Warning message control\n",
    "from pathlib import Path           # Modern path handling for cross-platform compatibility\n",
    "\n",
    "import pandas as pd               # Data manipulation and analysis framework\n",
    "from openpyxl import load_workbook # Excel file reading with formula support\n",
    "\n",
    "# === Suppress future warnings for cleaner output ===\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "# === Configure directory structure for FZ8 data pipeline ===\n",
    "DATA_DIR = Path(\"../data/raw/fz8\")            # Source Excel files directory\n",
    "OUT_DIR  = Path(\"../data/raw/fz8/csv\")        # Raw CSV output directory\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)    # Create output directory if missing\n",
    "\n",
    "DST_DIR = Path(\"../data/processed/,\")         # Processed data destination directory\n",
    "DST_DIR.mkdir(parents=True, exist_ok=True)    # Create destination directory if missing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db963102",
   "metadata": {},
   "source": [
    "## Data Processing Functions\n",
    "\n",
    "Helper functions for Excel parsing, text cleaning, and data standardization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9375ed68",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _clean_str(v):\n",
    "    \"\"\"\n",
    "    Normalize string values with consistent formatting rules.\n",
    "    \n",
    "    Args:\n",
    "        v: Input value (any type)\n",
    "        \n",
    "    Returns:\n",
    "        str: Normalized string or original value if not string\n",
    "    \"\"\"\n",
    "    # === Check if input is string type ===\n",
    "    if isinstance(v, str):\n",
    "        # === Collapse multiple whitespace characters into single space ===\n",
    "        normalized = re.sub(r\"\\s+\", \" \", v)\n",
    "        # === Remove leading/trailing whitespace and convert to uppercase ===\n",
    "        return normalized.strip().upper()\n",
    "    # === Return non-string values unchanged ===\n",
    "    return v\n",
    "\n",
    "\n",
    "def _filter_trash(df, column, pattern):\n",
    "    \"\"\"\n",
    "    Remove rows containing unwanted patterns from DataFrame.\n",
    "    \n",
    "    Args:\n",
    "        df (pd.DataFrame): Input DataFrame to filter\n",
    "        column (str): Column name to check for trash patterns\n",
    "        pattern (str): Regex pattern to identify trash rows\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame: Filtered DataFrame with clean index\n",
    "    \"\"\"\n",
    "    # === Compile regex pattern for case-insensitive matching ===\n",
    "    regex = re.compile(pattern, re.IGNORECASE)\n",
    "    \n",
    "    # === Define function to identify trash values ===\n",
    "    def is_trash(value):\n",
    "        # === Check if value is string and matches trash pattern ===\n",
    "        return isinstance(value, str) and regex.search(value) is not None\n",
    "    \n",
    "    # === Apply trash detection to target column ===\n",
    "    mask = df[column].apply(is_trash)\n",
    "    # === Return rows that are NOT trash, reset index for clean numbering ===\n",
    "    return df[~mask].reset_index(drop=True)\n",
    "\n",
    "\n",
    "def _clean_numeric(df, num_cols):\n",
    "    \"\"\"\n",
    "    Convert string columns to numeric with German formatting support.\n",
    "    \n",
    "    Args:\n",
    "        df (pd.DataFrame): Input DataFrame\n",
    "        num_cols: Column names to convert to numeric\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with cleaned numeric columns\n",
    "    \"\"\"\n",
    "    # === Replace common placeholder values with NA ===\n",
    "    df[num_cols] = (\n",
    "        df[num_cols]\n",
    "        .replace({'-': pd.NA, r'^\\.$': pd.NA}, regex=True)  # Dash and single dot to NA\n",
    "        .apply(pd.to_numeric, errors='coerce')              # Convert to numeric, invalid -> NaN\n",
    "    )\n",
    "\n",
    "    # === Mask zero values as missing data (optional data cleaning step) ===\n",
    "    df[num_cols] = df[num_cols].mask(df[num_cols] == 0)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def _extract_df(ws, columns_to_use, data_start, data_end):\n",
    "    \"\"\"\n",
    "    Extract structured data from Excel worksheet with header mapping.\n",
    "    \n",
    "    Args:\n",
    "        ws: Openpyxl worksheet object\n",
    "        columns_to_use (list): List of cell addresses for headers\n",
    "        data_start (int): First row number containing data\n",
    "        data_end (int): Last row number containing data\n",
    "        \n",
    "    Returns:\n",
    "        tuple: (DataFrame with extracted data, list of column names)\n",
    "    \"\"\"\n",
    "    # === Extract and clean header values from specified cells ===\n",
    "    raw = [_clean_header(ws[cell].value) for cell in columns_to_use]\n",
    "    # === Ensure unique column names by adding suffixes to duplicates ===\n",
    "    cols = _unique(raw)\n",
    "    # === Extract column letters from cell addresses (e.g., 'B' from 'B8') ===\n",
    "    letters = [re.match(r\"[A-Z]+\", cell).group() for cell in columns_to_use]\n",
    "\n",
    "    # === Build data dictionary by reading each column ===\n",
    "    data = {\n",
    "        col: _col(ws, letter, data_start, data_end)\n",
    "        for col, letter in zip(cols, letters)\n",
    "    }\n",
    "\n",
    "    # === Create DataFrame and remove completely empty rows ===\n",
    "    df = pd.DataFrame(data).dropna(how=\"all\")\n",
    "    # === Apply final column name cleaning ===\n",
    "    df = _strip_cols(df)\n",
    "\n",
    "    return df, cols\n",
    "\n",
    "\n",
    "def _date_from_fname(path):\n",
    "    \"\"\"\n",
    "    Extract date information from filename using multiple patterns.\n",
    "    \n",
    "    Args:\n",
    "        path: Path object with filename to parse\n",
    "        \n",
    "    Returns:\n",
    "        str: Date string extracted from filename\n",
    "        \n",
    "    Raises:\n",
    "        ValueError: If no recognized date pattern found\n",
    "    \"\"\"\n",
    "    name = path.name\n",
    "\n",
    "    # === Try YYYY pattern (e.g., 'file_2023.xlsx') ===\n",
    "    match = re.search(r\"(\\d{4})\", name)\n",
    "    if match:\n",
    "        return match.group(1)\n",
    "\n",
    "    # === Try YYYYMM pattern (e.g., 'file_202305.xlsx') ===\n",
    "    match = re.search(r\"(\\d{6})\", name)\n",
    "    if match:\n",
    "        return match.group(1)\n",
    "\n",
    "    # === Try YYYY_MM pattern (e.g., 'file_2023_05.xlsx') ===\n",
    "    match = re.search(r\"(\\d{4})_(\\d{2})\", name)\n",
    "    if match:\n",
    "        return match.group(1) + match.group(2)\n",
    "\n",
    "    # === No pattern matched, raise error with filename ===\n",
    "    raise ValueError(f\"No recognized date pattern in filename: {name}\")\n",
    "\n",
    "\n",
    "def _find_sheet(wb, sheet_num):\n",
    "    \"\"\"\n",
    "    Locate FZ sheet by number using pattern matching.\n",
    "    \n",
    "    Args:\n",
    "        wb: Openpyxl workbook object\n",
    "        sheet_num (str): Sheet number to find (e.g., '1', '2', '16')\n",
    "        \n",
    "    Returns:\n",
    "        str or None: Sheet name if found, None otherwise\n",
    "    \"\"\"\n",
    "    # === Compile pattern to match 'FZ X.Y' format ===\n",
    "    pattern = re.compile(r\"^FZ\\s*(\\d+)\\.(\\d+)$\", flags=re.IGNORECASE)\n",
    "\n",
    "    # === Search through all sheet names ===\n",
    "    for name in wb.sheetnames:\n",
    "        clean_name = name.strip()\n",
    "        match = pattern.match(clean_name)\n",
    "        # === Check if sheet number matches target ===\n",
    "        if match and match.group(2) == sheet_num:\n",
    "            return name\n",
    "\n",
    "    return None\n",
    "\n",
    "\n",
    "def _clean_header(s):\n",
    "    \"\"\"\n",
    "    Standardize header text with consistent formatting.\n",
    "    \n",
    "    Args:\n",
    "        s: Header value (string or None)\n",
    "        \n",
    "    Returns:\n",
    "        str: Cleaned header string or original if None\n",
    "    \"\"\"\n",
    "    # === Return None values unchanged ===\n",
    "    if s is None:\n",
    "        return s\n",
    "    \n",
    "    # === Apply comprehensive text cleaning ===\n",
    "    return (str(s)\n",
    "            .translate(str.maketrans(\"äÄöÖüÜ\", \"aAoOuU\"))  # Remove German umlauts\n",
    "            .replace(\"\\n\", \" \")                            # Replace newlines with spaces\n",
    "            .replace(\"  \", \" \")                            # Collapse double spaces\n",
    "            .strip()                                       # Remove leading/trailing whitespace\n",
    "            .upper())                                      # Convert to uppercase\n",
    "\n",
    "\n",
    "def _unique(cols):\n",
    "    \"\"\"\n",
    "    Generate unique column names by adding numeric suffixes.\n",
    "    \n",
    "    Args:\n",
    "        cols (list): List of potentially duplicate column names\n",
    "        \n",
    "    Returns:\n",
    "        list: List with unique names (duplicates get suffixes)\n",
    "    \"\"\"\n",
    "    seen, out = {}, []\n",
    "    # === Process each column name ===\n",
    "    for c in cols:\n",
    "        if c in seen:\n",
    "            # === Add numeric suffix for duplicates ===\n",
    "            seen[c] += 1\n",
    "            out.append(f\"{c}{seen[c]}\")\n",
    "        else:\n",
    "            # === First occurrence, no suffix needed ===\n",
    "            seen[c] = 0\n",
    "            out.append(c)\n",
    "    return out\n",
    "\n",
    "\n",
    "def _col(ws, letter, r0, r1):\n",
    "    \"\"\"\n",
    "    Read values from specific Excel column within row range.\n",
    "    \n",
    "    Args:\n",
    "        ws: Openpyxl worksheet object\n",
    "        letter (str): Column letter (e.g., 'A', 'B', 'AA')\n",
    "        r0 (int): Starting row number (inclusive)\n",
    "        r1 (int): Ending row number (inclusive)\n",
    "        \n",
    "    Returns:\n",
    "        list: Cell values from specified column range\n",
    "    \"\"\"\n",
    "    # === Read each cell value in the specified range ===\n",
    "    return [ws[f\"{letter}{row}\"].value for row in range(r0, r1 + 1)]\n",
    "\n",
    "\n",
    "def _strip_cols(df):\n",
    "    \"\"\"\n",
    "    Apply header cleaning to all DataFrame column names.\n",
    "    \n",
    "    Args:\n",
    "        df (pd.DataFrame): DataFrame with potentially messy column names\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with cleaned column names\n",
    "    \"\"\"\n",
    "    # === Clean all column names using header cleaning function ===\n",
    "    df.columns = [_clean_header(c) for c in df.columns]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fcf7f91",
   "metadata": {},
   "source": [
    "## Sheet Configuration Dictionary\n",
    "\n",
    "Define parsing rules for each FZ8 sheet including column mappings, data\n",
    "ranges, and trash row patterns for automated filtering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "24ca8e61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Master configuration dictionary for all FZ8 sheet parsing ===\n",
    "CONFIG = {\n",
    "    # === FZ8.1: Basic vehicle registration data (2 columns) ===\n",
    "    '1': {\n",
    "        'columns_to_use': [\"B8\", \"C9\"],                          # Header cell addresses\n",
    "        'data_start': 10,                                        # First data row\n",
    "        'data_end': 100,                                         # Last data row to scan\n",
    "        'trash': r\"INSGESAMT|FLENSBURG|HINWEIS|UMBENANNT\",       # Regex pattern for metadata rows\n",
    "    },\n",
    "    # === FZ8.2: Extended vehicle statistics (7 columns) ===\n",
    "    '2': {\n",
    "        'columns_to_use': [\"B8\", \"C8\", \"D8\", \"F9\", \"I9\", \"J9\", \"K10\"],  # Mixed header row positions\n",
    "        'data_start': 11,                                        # Data starts row 11\n",
    "        'data_end': 100,                                         # Scan up to row 100\n",
    "        'trash': r\"INSGESAMT|FLENSBURG|HINWEIS|UMBENANNT\",       # Standard metadata patterns\n",
    "    },\n",
    "    # === FZ8.3: Comprehensive vehicle analysis (15 columns) ===\n",
    "    '3': {\n",
    "        'columns_to_use': [\"B8\", \"C8\", \"D8\", \"E10\", \"F9\", \"G10\", \"H10\", \"I9\", \"J10\", \"K10\", \"L9\", \"M9\", \"N9\", \"O10\", \"P9\"],  # Complex header layout\n",
    "        'data_start': 11,                                        # Data starts row 11\n",
    "        'data_end': 500,                                         # Large data range\n",
    "        'trash': r\"ZUSAMMEN|INSGESAMT|HINWEISE|AUSGEWIESEN|KRAFTSTOFFVERBRAUCH|FLENSBURG|HINWEIS|UMBENANNT\",  # Extended trash patterns\n",
    "    },\n",
    "    # === FZ8.6: Regional vehicle distribution (11 columns) ===\n",
    "    '6': {\n",
    "        'columns_to_use': [\"B8\", \"C8\", \"D8\", \"G8\", \"H8\", \"K8\", \"L8\", \"M8\", \"N8\", \"O9\", \"P8\"],  # Geographic data\n",
    "        'data_start': 10,                                        # Standard data start\n",
    "        'data_end': 30,                                          # Small geographic dataset\n",
    "        'trash': r\"FLENSBURG|HINWEIS|UMBENANNT\",                 # Minimal trash patterns\n",
    "    },\n",
    "    # === FZ8.7: Age and usage analysis (13 columns) ===\n",
    "    '7': {\n",
    "        'columns_to_use': [\"B8\", \"C8\", \"D9\", \"E9\", \"F9\", \"G9\", \"H9\", \"I9\", \"J9\", \"K9\", \"L9\", \"M9\", \"N9\"],  # Age cohort data\n",
    "        'data_start': 10,                                        # Standard data start\n",
    "        'data_end': 100,                                         # Moderate data range\n",
    "        'trash': r\"INSGESAMT|DARUNTER|FLENSBURG|HINWEIS|UMBENANNT\",  # Age-specific trash\n",
    "    },\n",
    "    # === FZ8.8: Engine specifications (7 columns) ===\n",
    "    '8': {\n",
    "        'columns_to_use': [\"B8\", \"C10\", \"D10\", \"E10\", \"F10\", \"G9\", \"H9\"],  # Technical specifications\n",
    "        'data_start': 11,                                        # Data starts row 11\n",
    "        'data_end': 35,                                          # Compact technical data\n",
    "        'trash': r\"HINWEIS|HUBRAUM|FLENSBURG|UMBENANNT|UNBEKANNT|ZUSAMMEN|WEIBLICHE|UNBEKANNT|INSGESAMT|DARUNTER\",  # Technical trash patterns\n",
    "    },\n",
    "    # === FZ8.9: Commercial vehicle analysis (10 columns) ===\n",
    "    '9': {\n",
    "        'columns_to_use': [\"B8\", \"C8\", \"D8\", \"F8\", \"H9\", \"J9\", \"L9\", \"N9\", \"P9\", \"R8\"],  # Commercial vehicle data\n",
    "        'data_start': 11,                                        # Data starts row 11\n",
    "        'data_end': 100,                                         # Standard data range\n",
    "        'trash': r\"INSGESAMT|HINWEIS|ERBRINGUNG|FLENSBURG|UMBENANNT\",  # Commercial-specific trash\n",
    "    },\n",
    "    # === FZ8.16: Special vehicle categories (3 columns) ===\n",
    "    '16': {\n",
    "        'columns_to_use': [\"B8\", \"C8\", \"D9\"],                   # Special category data\n",
    "        'data_start': 11,                                        # Data starts row 11\n",
    "        'data_end': 50,                                          # Small special category dataset\n",
    "        'trash': r\"INSGESAMT|HINWEIS|SATTELANHÄNGER|VERORDNUNG|FLENSBURG\",  # Special category trash\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "749636f7",
   "metadata": {},
   "source": [
    "## Sheet Parser Functions\n",
    "\n",
    "Specialized functions for processing individual FZ8 sheets with sheet-specific\n",
    "logic and validation rules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5c3fe88a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fz8_1(ws):\n",
    "    \"\"\"\n",
    "    Parse FZ8.1 sheet with basic two-column structure.\n",
    "    \n",
    "    Args:\n",
    "        ws: Openpyxl worksheet object for FZ8.1 sheet\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame: Cleaned DataFrame with standardized formatting\n",
    "    \"\"\"\n",
    "    # === Load sheet configuration from CONFIG dictionary ===\n",
    "    cfg = CONFIG['1']\n",
    "\n",
    "    # === Extract headers and column mappings using configured cell addresses ===\n",
    "    df, cols = _extract_df(ws, cfg['columns_to_use'], cfg['data_start'], cfg['data_end'])\n",
    "\n",
    "    # === Normalize all string cells (trim whitespace, uppercase) ===\n",
    "    df = df.applymap(_clean_str)\n",
    "    \n",
    "    # === Remove trash rows based on first column using regex patterns ===\n",
    "    df = _filter_trash(df, cols[0], cfg['trash'])\n",
    "\n",
    "    # === Convert numeric columns (all except first label column) ===\n",
    "    num_cols = cols[1:]  # Skip first column (assumed to be text labels)\n",
    "    df = _clean_numeric(df, num_cols)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "87a3c1b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fz8_2(ws):\n",
    "    \"\"\"\n",
    "    Parse FZ8.2 sheet containing extended vehicle statistics.\n",
    "    \n",
    "    Args:\n",
    "        ws: Openpyxl worksheet object for FZ8.2 sheet\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame: Cleaned DataFrame with extended vehicle statistics\n",
    "    \"\"\"\n",
    "    # === Sheet configuration from CONFIG dictionary\n",
    "    cfg = CONFIG['2']\n",
    "\n",
    "    # === Extract headers and column mappings\n",
    "    df, cols = _extract_df(ws, cfg['columns_to_use'], cfg['data_start'], cfg['data_end'])\n",
    "\n",
    "    # === Normalize all string cells\n",
    "    df = df.applymap(_clean_str)\n",
    "    \n",
    "    # === Remove trash rows based on first column\n",
    "    df = _filter_trash(df, cols[0], cfg['trash'])\n",
    "\n",
    "    # === Convert numeric columns (all except first label column)\n",
    "    num_cols = cols[1:]  # Skip first column (assumed to be text labels)\n",
    "    df = _clean_numeric(df, num_cols)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f2517109",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fz8_3(ws):\n",
    "    \"\"\"\n",
    "    Parse FZ8.3 sheet containing comprehensive vehicle analysis with segments.\n",
    "    \n",
    "    Args:\n",
    "        ws: Openpyxl worksheet object for FZ8.3 sheet\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame: Cleaned DataFrame with comprehensive vehicle analysis\n",
    "    \"\"\"\n",
    "    # === Sheet configuration from CONFIG dictionary\n",
    "    cfg = CONFIG['3']\n",
    "\n",
    "    # === Extract headers and column mappings\n",
    "    df, cols = _extract_df(ws, cfg['columns_to_use'], cfg['data_start'], cfg['data_end'])\n",
    "\n",
    "    # === Fill missing segment values (forward-fill grouped data structure)\n",
    "    seg_col = next((c for c in df.columns if \"segment\" in str(c).lower()), df.columns[0])\n",
    "    df[seg_col] = df[seg_col].ffill()\n",
    "\n",
    "    # === Remove trash rows based on segment column\n",
    "    df = _filter_trash(df, seg_col, cfg['trash'])\n",
    "\n",
    "    # === Special handling for SONSTIGE in segment column\n",
    "    mod_col = next((c for c in df.columns if \"modellreihe\" in str(c).lower()), None)\n",
    "    if mod_col:\n",
    "        # === Mark SONSTIGE entries in model series column for clarity\n",
    "        df.loc[df[seg_col].astype(str).str.contains(r\"\\bSONSTIGE\\b\", case=False, na=False), mod_col] = \"SONSTIGE\"\n",
    "\n",
    "    # === Normalize all string cells\n",
    "    df = df.applymap(_clean_str)\n",
    "\n",
    "    # === Clean numeric columns (exclude segment and modellreihe text columns)\n",
    "    drop_cols = [seg_col]\n",
    "    if mod_col:\n",
    "        drop_cols.append(mod_col)\n",
    "\n",
    "    num_cols = df.columns.drop(drop_cols, errors=\"ignore\")\n",
    "    df = _clean_numeric(df, num_cols)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "488ab84c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fz8_6(ws):\n",
    "    \"\"\"\n",
    "    Parse FZ8.6 sheet containing regional vehicle distribution data.\n",
    "    \n",
    "    Args:\n",
    "        ws: Openpyxl worksheet object for FZ8.6 sheet\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame: Cleaned DataFrame with regional vehicle distribution\n",
    "    \"\"\"\n",
    "    # === Sheet configuration from CONFIG dictionary\n",
    "    cfg = CONFIG['6']\n",
    "\n",
    "    # === Extract headers and column mappings\n",
    "    df, cols = _extract_df(ws, cfg['columns_to_use'], cfg['data_start'], cfg['data_end'])\n",
    "\n",
    "    # === Normalize all string cells\n",
    "    df = df.applymap(_clean_str)\n",
    "    \n",
    "    # === Remove trash rows based on first column\n",
    "    df = _filter_trash(df, cols[0], cfg['trash'])\n",
    "\n",
    "    # === Convert numeric columns (all except first geographic label column)\n",
    "    num_cols = cols[1:]  # Skip first column (geographic identifiers)\n",
    "    df = _clean_numeric(df, num_cols)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d2806cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fz8_7(ws):\n",
    "    \"\"\"\n",
    "    Parse FZ8.7 sheet containing age and usage analysis data.\n",
    "    \n",
    "    Args:\n",
    "        ws: Openpyxl worksheet object for FZ8.7 sheet\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame: Cleaned DataFrame with age and usage analysis\n",
    "    \"\"\"\n",
    "    # === Sheet configuration from CONFIG dictionary\n",
    "    cfg = CONFIG['7']\n",
    "\n",
    "    # === Extract headers and column mappings\n",
    "    df, cols = _extract_df(ws, cfg['columns_to_use'], cfg['data_start'], cfg['data_end'])\n",
    "\n",
    "    # === Normalize all string cells\n",
    "    df = df.applymap(_clean_str)\n",
    "    \n",
    "    # === Remove trash rows based on first column\n",
    "    df = _filter_trash(df, cols[0], cfg['trash'])\n",
    "\n",
    "    # === Convert numeric columns (all except first age group label column)\n",
    "    num_cols = cols[1:]  # Skip first column (age group identifiers)\n",
    "    df = _clean_numeric(df, num_cols)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "99e42a88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fz8_8(ws):\n",
    "    \"\"\"\n",
    "    Parse FZ8.8 sheet containing engine specifications and technical data.\n",
    "    \n",
    "    Args:\n",
    "        ws: Openpyxl worksheet object for FZ8.8 sheet\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame: Cleaned DataFrame with engine specifications\n",
    "    \"\"\"\n",
    "    # === Sheet configuration from CONFIG dictionary\n",
    "    cfg = CONFIG['8']\n",
    "\n",
    "    # === Extract headers and column mappings\n",
    "    df, cols = _extract_df(ws, cfg['columns_to_use'], cfg['data_start'], cfg['data_end'])\n",
    "\n",
    "    # === Normalize all string cells\n",
    "    df = df.applymap(_clean_str)\n",
    "    \n",
    "    # === Remove trash rows based on first column\n",
    "    df = _filter_trash(df, cols[0], cfg['trash'])\n",
    "\n",
    "    # === Convert numeric columns (all except first specification label column)\n",
    "    num_cols = cols[1:]  # Skip first column (technical specification labels)\n",
    "    df = _clean_numeric(df, num_cols)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9d9fbe93",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fz8_9(ws):\n",
    "    \"\"\"\n",
    "    Parse FZ8.9 sheet containing commercial vehicle analysis data.\n",
    "    \n",
    "    Args:\n",
    "        ws: Openpyxl worksheet object for FZ8.9 sheet\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame: Cleaned DataFrame with commercial vehicle analysis\n",
    "    \"\"\"\n",
    "    # === Sheet configuration from CONFIG dictionary\n",
    "    cfg = CONFIG['9']\n",
    "\n",
    "    # === Extract headers and column mappings\n",
    "    df, cols = _extract_df(ws, cfg['columns_to_use'], cfg['data_start'], cfg['data_end'])\n",
    "\n",
    "    # === Normalize all string cells\n",
    "    df = df.applymap(_clean_str)\n",
    "    \n",
    "    # === Remove trash rows based on first column\n",
    "    df = _filter_trash(df, cols[0], cfg['trash'])\n",
    "\n",
    "    # === Convert numeric columns (all except first commercial category label column)\n",
    "    num_cols = cols[1:]  # Skip first column (commercial vehicle category labels)\n",
    "    df = _clean_numeric(df, num_cols)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2bc4610f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fz8_16(ws):\n",
    "    \"\"\"\n",
    "    Parse FZ8.16 sheet containing special vehicle categories data.\n",
    "    \n",
    "    Args:\n",
    "        ws: Openpyxl worksheet object for FZ8.16 sheet\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame: Cleaned DataFrame with special vehicle categories\n",
    "    \"\"\"\n",
    "    # === Sheet configuration from CONFIG dictionary\n",
    "    cfg = CONFIG['16']\n",
    "\n",
    "    # === Extract headers and column mappings\n",
    "    df, cols = _extract_df(ws, cfg['columns_to_use'], cfg['data_start'], cfg['data_end'])\n",
    "\n",
    "    # === Normalize all string cells\n",
    "    df = df.applymap(_clean_str)\n",
    "    \n",
    "    # === Remove trash rows based on first column\n",
    "    df = _filter_trash(df, cols[0], cfg['trash'])\n",
    "\n",
    "    # === Convert numeric columns (all except first special category label column)\n",
    "    num_cols = cols[1:]  # Skip first column (special vehicle category labels)\n",
    "    df = _clean_numeric(df, num_cols)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4047b9fa",
   "metadata": {},
   "source": [
    "## Data Validation Function\n",
    "\n",
    "Comprehensive validation of FZ8 sheet layouts across all Excel files to ensure\n",
    "consistency in headers, column positions, and data ranges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "89a22850",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ The layouts of all sheets are identical (coordinates, headers, first data row)\n"
     ]
    }
   ],
   "source": [
    "def check_layout():\n",
    "    \"\"\"\n",
    "    Validate layout consistency across all FZ8 Excel files.\n",
    "    \n",
    "    Checks for consistency in:\n",
    "    - Header names and positions\n",
    "    - Data start row positions\n",
    "    - Sheet existence across files\n",
    "    \n",
    "    Prints validation results and any discrepancies found.\n",
    "    \"\"\"\n",
    "    # === Initialize issue tracking list ===\n",
    "    issues = []\n",
    "\n",
    "    # === Validate each configured sheet type ===\n",
    "    for num, cfg in CONFIG.items():\n",
    "        ref_names = None  # Reference header names for comparison\n",
    "        ref_file = None   # Reference file name for reporting\n",
    "\n",
    "        # === Check consistency across all FZ8 Excel files ===\n",
    "        for path in sorted(DATA_DIR.glob(\"fz8_*.xlsx\")):\n",
    "            # === Load workbook in data-only mode ===\n",
    "            wb = load_workbook(path, data_only=True)\n",
    "            # === Find the specific FZ sheet by its number ===\n",
    "            sn = _find_sheet(wb, num)\n",
    "            if not sn:\n",
    "                issues.append(f\"{path.name}: workbook x.{num} not found\")\n",
    "                continue\n",
    "\n",
    "            # === Extract headers from configured cell positions ===\n",
    "            ws = wb[sn]\n",
    "            names = [_clean_header(ws[c].value) for c in cfg['columns_to_use']]\n",
    "\n",
    "            # === Establish reference headers from first file ===\n",
    "            if ref_names is None:\n",
    "                ref_names, ref_file = names, path.name\n",
    "            # === Compare headers against reference ===\n",
    "            elif names != ref_names:\n",
    "                issues.append(f\"{path.name}: x.{num} – {names} ≠ {ref_names} (reference {ref_file})\")\n",
    "\n",
    "            # === Validate data start row is not empty ===\n",
    "            row = cfg['data_start']\n",
    "            if not any(ws[f\"{c[0]}{row}\"].value for c in cfg['columns_to_use']):\n",
    "                issues.append(f\"{path.name}: x.{num} – row {row} is empty, first data row shifted?\")\n",
    "\n",
    "    # === Report validation results ===\n",
    "    if issues:\n",
    "        print(\"⚠️ Discrepancies have been detected:\")\n",
    "        for msg in issues:\n",
    "            print(\" •\", msg)\n",
    "    else:\n",
    "        print(\"✓ The layouts of all sheets are identical (coordinates, headers, first data row)\")\n",
    "\n",
    "# === Execute layout validation ===\n",
    "check_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accce272",
   "metadata": {},
   "source": [
    "## Parser Configuration and Results Storage\n",
    "\n",
    "Map sheet numbers to their respective parser functions and initialize \n",
    "result storage containers for processed data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cc973d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Map sheet numbers to their specific parser functions ===\n",
    "sheet_parsers = {\n",
    "    \"2\":  fz8_2,   # Extended vehicle statistics parser\n",
    "    \"3\":  fz8_3,   # Comprehensive vehicle analysis parser  \n",
    "    \"6\":  fz8_6,   # Regional vehicle distribution parser\n",
    "    \"7\":  fz8_7,   # Age and usage analysis parser\n",
    "    \"8\":  fz8_8,   # Engine specifications parser\n",
    "    \"9\":  fz8_9,   # Commercial vehicle analysis parser\n",
    "    \"16\": fz8_16,  # Special vehicle categories parser\n",
    "}\n",
    "\n",
    "# === Initialize result storage for each sheet type ===\n",
    "results = {num: [] for num in sheet_parsers}  # Will hold DataFrames from each file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b10ceb12",
   "metadata": {},
   "source": [
    "## Main Processing Pipeline\n",
    "\n",
    "Process all FZ8 Excel files, parse each configured sheet, add date information,\n",
    "and accumulate results for subsequent CSV export."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e6aa3024",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Process all FZ8 Excel files in chronological order ===\n",
    "for path in sorted(DATA_DIR.glob(\"fz8_*.xlsx\")):\n",
    "    # === Load workbook in data-only mode for faster processing ===\n",
    "    wb = load_workbook(path, data_only=True)\n",
    "    # === Extract date from filename for time series tracking ===\n",
    "    date = _date_from_fname(path)\n",
    "\n",
    "    # === Process each configured sheet within the workbook ===\n",
    "    for num, parser in sheet_parsers.items():\n",
    "        # === Locate the specific FZ sheet by number ===\n",
    "        sname = _find_sheet(wb, num)\n",
    "        if not sname:\n",
    "            print(f\"{path.name}: workbook 8.{num} not found\")\n",
    "            continue\n",
    "\n",
    "        # === Apply sheet-specific parser with error handling ===\n",
    "        try:\n",
    "            df = parser(wb[sname])                 # Parse sheet data\n",
    "            df.insert(0, \"DATE\", date)             # Add date column for time series\n",
    "            results[num].append(df)                # Store result for later concatenation\n",
    "        except Exception as e:\n",
    "            print(f\"{path.name}: error processing 8.{num} – {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e83ad2df",
   "metadata": {},
   "source": [
    "## CSV Export and Data Summary\n",
    "\n",
    "Concatenate processed DataFrames by sheet type, standardize text encoding,\n",
    "and export to CSV files with comprehensive data summary output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bce990a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "• Saved fz_8.2_2023-2025_raw.csv  →  (1653, 8)\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1653 entries, 0 to 1652\n",
      "Data columns (total 8 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   DATE                  1653 non-null   object \n",
      " 1   MARKE                 1653 non-null   object \n",
      " 2   ANZAHL                1653 non-null   float64\n",
      " 3   CO2-EMISSION IN G/KM  1374 non-null   float64\n",
      " 4   EURO 6                1386 non-null   float64\n",
      " 5   ELEKTRO (BEV)         1197 non-null   float64\n",
      " 6   HYBRID                1091 non-null   float64\n",
      " 7   DARUNTER PLUG-IN      923 non-null    float64\n",
      "dtypes: float64(6), object(2)\n",
      "memory usage: 103.4+ KB\n",
      "\n",
      "\n",
      "\n",
      "• Saved fz_8.3_2023-2025_raw.csv  →  (10146, 16)\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10146 entries, 0 to 10145\n",
      "Data columns (total 16 columns):\n",
      " #   Column                                Non-Null Count  Dtype  \n",
      "---  ------                                --------------  -----  \n",
      " 0   DATE                                  10146 non-null  object \n",
      " 1   SEGMENT                               10146 non-null  object \n",
      " 2   MODELLREIHE                           10146 non-null  object \n",
      " 3   INSGESAMT                             10146 non-null  float64\n",
      " 4   CO2-EMISSION IN G/KM                  8268 non-null   float64\n",
      " 5   BENZIN                                5544 non-null   float64\n",
      " 6   CO2-EMISSION IN G/KM1                 5319 non-null   float64\n",
      " 7   KRAFTSTOFFVERBRAUCH IN L/100 KM       5319 non-null   float64\n",
      " 8   DIESEL                                3746 non-null   float64\n",
      " 9   CO2-EMISSION IN G/KM2                 3462 non-null   float64\n",
      " 10  KRAFTSTOFFVERBRAUCH IN L/100 KM1      3462 non-null   float64\n",
      " 11  ERDGAS (CNG) (EINSCHL. BIVALENT)      177 non-null    float64\n",
      " 12  FLUSSIGGAS (LPG) (EINSCHL. BIVALENT)  213 non-null    float64\n",
      " 13  HYBRID                                4883 non-null   float64\n",
      " 14  DAR. PLUG-IN                          2814 non-null   float64\n",
      " 15  ELEKTRO (BEV)                         3163 non-null   float64\n",
      "dtypes: float64(13), object(3)\n",
      "memory usage: 1.2+ MB\n",
      "\n",
      "\n",
      "\n",
      "• Saved fz_8.6_2023-2025_raw.csv  →  (504, 12)\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 504 entries, 0 to 503\n",
      "Data columns (total 12 columns):\n",
      " #   Column                                Non-Null Count  Dtype  \n",
      "---  ------                                --------------  -----  \n",
      " 0   DATE                                  504 non-null    object \n",
      " 1   BUNDESLAND                            504 non-null    object \n",
      " 2   BENZIN INSGESAMT                      504 non-null    float64\n",
      " 3   DARUNTER EURO 6                       504 non-null    float64\n",
      " 4   DIESEL INSGESAMT                      504 non-null    float64\n",
      " 5   DARUNTER EURO 61                      504 non-null    float64\n",
      " 6   FLUSSIGGAS (LPG) (EINSCHL. BIVALENT)  482 non-null    float64\n",
      " 7   ERDGAS (CNG) (EINSCHL. BIVALENT)      230 non-null    float64\n",
      " 8   ELEKTRO (BEV)                         504 non-null    float64\n",
      " 9   HYBRID                                504 non-null    float64\n",
      " 10  DARUNTER PLUG-IN                      504 non-null    float64\n",
      " 11  SONSTIGE                              214 non-null    float64\n",
      "dtypes: float64(10), object(2)\n",
      "memory usage: 47.4+ KB\n",
      "\n",
      "\n",
      "\n",
      "• Saved fz_8.7_2023-2025_raw.csv  →  (1657, 14)\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1657 entries, 0 to 1656\n",
      "Data columns (total 14 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   DATE          1657 non-null   object \n",
      " 1   MARKE         1657 non-null   object \n",
      " 2   INSGESAMT     1657 non-null   float64\n",
      " 3   WEISS         1522 non-null   float64\n",
      " 4   GELB          951 non-null    float64\n",
      " 5   ORANGE        750 non-null    float64\n",
      " 6   ROT           1286 non-null   float64\n",
      " 7   LILA/VIOLETT  446 non-null    float64\n",
      " 8   BLAU          1479 non-null   float64\n",
      " 9   GRUN          1226 non-null   float64\n",
      " 10  GRAU          1564 non-null   float64\n",
      " 11  BRAUN         825 non-null    float64\n",
      " 12  SCHWARZ       1559 non-null   float64\n",
      " 13  SONSTIGE      693 non-null    float64\n",
      "dtypes: float64(12), object(2)\n",
      "memory usage: 181.4+ KB\n",
      "\n",
      "\n",
      "\n",
      "• Saved fz_8.8_2023-2025_raw.csv  →  (448, 8)\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 448 entries, 0 to 447\n",
      "Data columns (total 8 columns):\n",
      " #   Column                                  Non-Null Count  Dtype  \n",
      "---  ------                                  --------------  -----  \n",
      " 0   DATE                                    448 non-null    object \n",
      " 1   LEBENSALTER DER HALTERINNEN UND HALTER  448 non-null    object \n",
      " 2   BIS 1399                                448 non-null    float64\n",
      " 3   1400 BIS 1999                           448 non-null    float64\n",
      " 4   2000 UND MEHR                           448 non-null    float64\n",
      " 5   UNBEKANNT                               437 non-null    float64\n",
      " 6   INSGESAMT                               448 non-null    float64\n",
      " 7   DARUNTER HALTERINNEN                    420 non-null    float64\n",
      "dtypes: float64(6), object(2)\n",
      "memory usage: 28.1+ KB\n",
      "\n",
      "\n",
      "\n",
      "• Saved fz_8.9_2023-2025_raw.csv  →  (1653, 11)\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1653 entries, 0 to 1652\n",
      "Data columns (total 11 columns):\n",
      " #   Column                                       Non-Null Count  Dtype  \n",
      "---  ------                                       --------------  -----  \n",
      " 0   DATE                                         1653 non-null   object \n",
      " 1   MARKE                                        1653 non-null   object \n",
      " 2   INSGESAMT                                    1653 non-null   float64\n",
      " 3   PRIVATE HALTERINNEN UND HALTER               1580 non-null   float64\n",
      " 4   GEWERBLICHE HALTERINNEN UND HALTER           1632 non-null   float64\n",
      " 5   KFZ-HANDEL                                   1554 non-null   float64\n",
      " 6   KFZ-HERSTELLUNG                              1036 non-null   float64\n",
      " 7   KFZ-VERMIETUNG UND CARSHARING                1284 non-null   float64\n",
      " 8   ERBRINGUNG SONSTIGER DIENSTLEISTUNGEN        1523 non-null   float64\n",
      " 9   SONSTIGE GEWERBLICHE HALTERINNEN UND HALTER  1525 non-null   float64\n",
      " 10  UNBEKANNT                                    639 non-null    float64\n",
      "dtypes: float64(9), object(2)\n",
      "memory usage: 142.2+ KB\n",
      "\n",
      "\n",
      "\n",
      "• Saved fz_8.16_2023-2025_raw.csv  →  (924, 4)\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 924 entries, 0 to 923\n",
      "Data columns (total 4 columns):\n",
      " #   Column                       Non-Null Count  Dtype  \n",
      "---  ------                       --------------  -----  \n",
      " 0   DATE                         924 non-null    object \n",
      " 1   ZULASSIGE GESAMTMASSE IN KG  924 non-null    object \n",
      " 2   PERSONENKRAFTWAGEN           513 non-null    float64\n",
      " 3   DARUNTER WOHNMOBILE          381 non-null    float64\n",
      "dtypes: float64(2), object(2)\n",
      "memory usage: 29.0+ KB\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# === Export concatenated results to CSV files ===\n",
    "for num, frames in results.items():\n",
    "    # === Skip empty results (no data found for this sheet type) ===\n",
    "    if not frames:\n",
    "        continue\n",
    "\n",
    "    # === Concatenate all DataFrames for this sheet type ===\n",
    "    df = pd.concat(frames, ignore_index=True)\n",
    "    \n",
    "    # === Standardize text columns (fill NaN values, ensure string type) ===\n",
    "    obj_cols = df.select_dtypes(include=\"object\").columns\n",
    "    df[obj_cols] = df[obj_cols].fillna('').astype(str)\n",
    "\n",
    "    # === Export to CSV with UTF-8 encoding ===\n",
    "    out_csv = OUT_DIR / f\"fz_8.{num}_2023-2025_raw.csv\"\n",
    "    df.to_csv(out_csv, index=False, encoding=\"utf-8\", na_rep='')\n",
    "\n",
    "    # === Display export confirmation and data summary ===\n",
    "    print(f\"• Saved {out_csv.name}  →  {df.shape}\\n\")\n",
    "    df.info()  # Show column types, memory usage, and data statistics\n",
    "    print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f97968e",
   "metadata": {},
   "source": [
    "## Historical Data Integration\n",
    "\n",
    "Merge 2023-2025 data with existing 2020-2022 datasets, validate header consistency,\n",
    "and create unified time series CSV files spanning the complete data range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0960813f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fz_8.2_raw.csv  →  (2949, 8)\n",
      "fz_8.3_raw.csv  →  (21820, 16)\n",
      "fz_8.6_raw.csv  →  (936, 12)\n",
      "fz_8.7_raw.csv  →  (2953, 14)\n",
      "fz_8.8_raw.csv  →  (1024, 8)\n",
      "fz_8.9_raw.csv  →  (2949, 11)\n",
      "fz_8.16_raw.csv  →  (2112, 4)\n",
      "\n",
      "✓ All sheets have been successfully validated and merged.\n"
     ]
    }
   ],
   "source": [
    "# === Define sheet numbers to merge with historical data ===\n",
    "sheet_nums = [\"2\", \"3\", \"6\", \"7\", \"8\", \"9\", \"16\"]\n",
    "issues = []\n",
    "\n",
    "# === Process each sheet type for historical integration ===\n",
    "for num in sheet_nums:\n",
    "    # === Define file paths for both time periods ===\n",
    "    f_old = OUT_DIR / f\"fz_8.{num}_2020-2022_raw.csv\"    # Historical data file\n",
    "    f_new = OUT_DIR / f\"fz_8.{num}_2023-2025_raw.csv\"    # Current period data file\n",
    "\n",
    "    # === Validate both files exist ===\n",
    "    if not f_old.exists() or not f_new.exists():\n",
    "        issues.append(f\"8.{num}: missing {'old' if not f_old.exists() else 'new'} file\")\n",
    "        continue\n",
    "\n",
    "    # === Load both datasets ===\n",
    "    df_old = pd.read_csv(f_old, encoding=\"utf-8\")\n",
    "    df_new = pd.read_csv(f_new, encoding=\"utf-8\")\n",
    "\n",
    "    # === Validate header consistency between time periods ===\n",
    "    if list(df_old.columns) != list(df_new.columns):\n",
    "        issues.append(\n",
    "            f\"8.{num}: header mismatch.\\n\"\n",
    "            f\"  old: {list(df_old.columns)}\\n\"\n",
    "            f\"  new: {list(df_new.columns)}\"\n",
    "        )\n",
    "        continue\n",
    "\n",
    "    # === Merge historical and current data ===\n",
    "    df_all = pd.concat([df_old, df_new], ignore_index=True)\n",
    "\n",
    "    # === Standardize text columns for consistent CSV output ===\n",
    "    obj_cols = df_all.select_dtypes(include=\"object\").columns\n",
    "    df_all[obj_cols] = df_all[obj_cols].fillna(\"\")\n",
    "\n",
    "    # === Export unified time series data ===\n",
    "    out_csv = DST_DIR / f\"fz_08.{num}_raw.csv\"\n",
    "    df_all.to_csv(out_csv, index=False, encoding=\"utf-8\")\n",
    "    print(f\"fz_8.{num}_raw.csv  →  {df_all.shape}\")\n",
    "    # df_all.info()  # Uncomment for detailed data summary\n",
    "\n",
    "# === Report integration results ===\n",
    "if issues:\n",
    "    print(\"\\n⚠️ Discrepancies detected:\")\n",
    "    for msg in issues:\n",
    "        print(\" •\", msg)\n",
    "else:\n",
    "    print(\"\\n✓ All sheets have been successfully validated and merged.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
