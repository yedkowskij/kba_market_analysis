{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5346aa12",
   "metadata": {},
   "source": [
    "# PUSH ALL DATA TO DATABASE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d524c8fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Upload processed CSV files into PostgreSQL tables.\n",
    "\n",
    "This script will:\n",
    "1. Load database connection parameters from a .env file.\n",
    "2. Create a SQLAlchemy engine.\n",
    "3. Iterate over every CSV in ../data/processed.\n",
    "4. Read each CSV as text-only into a pandas DataFrame.\n",
    "5. Map every column to SQL TEXT type.\n",
    "6. Replace (or create) the corresponding table in the target schema.\n",
    "\"\"\"\n",
    "\n",
    "from pathlib import Path\n",
    "from dotenv import dotenv_values\n",
    "import pandas as pd\n",
    "import re\n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy.types import Text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d0ca5f2",
   "metadata": {},
   "source": [
    "## LOAD CONFIG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f24ecca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read .env into a dict of strings\n",
    "config    = dotenv_values()\n",
    "\n",
    "# Extract Postgres credentials / connection info\n",
    "pg_user   = config['POSTGRES_USER']\n",
    "pg_pass   = config['POSTGRES_PASS']\n",
    "pg_host   = config['POSTGRES_HOST']\n",
    "pg_port   = config['POSTGRES_PORT']\n",
    "pg_db     = config['POSTGRES_DB']\n",
    "pg_schema = config['POSTGRES_SCHEMA']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "55223a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the SQLAlchemy database URL\n",
    "db_url = f\"postgresql://{pg_user}:{pg_pass}@{pg_host}:{pg_port}/{pg_db}\"\n",
    "\n",
    "# This engine will manage connections & SQL execution\n",
    "engine = create_engine(db_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3dab83c",
   "metadata": {},
   "source": [
    "## PROCESS CSV FILES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7048141e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 517655 entries, 0 to 517654\n",
      "Data columns (total 7 columns):\n",
      " #   Column             Non-Null Count   Dtype \n",
      "---  ------             --------------   ----- \n",
      " 0   Berichtszeitpunkt  517655 non-null  object\n",
      " 1   Hersteller         517655 non-null  object\n",
      " 2   Handelsname        517655 non-null  object\n",
      " 3   Typschlüssel       517655 non-null  object\n",
      " 4   Bundesland         517655 non-null  object\n",
      " 5   Anzahl             517655 non-null  int64 \n",
      " 6   ObjectId           517655 non-null  int64 \n",
      "dtypes: int64(2), object(5)\n",
      "memory usage: 27.6+ MB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 21924 entries, 0 to 21923\n",
      "Data columns (total 21 columns):\n",
      " #   Column                        Non-Null Count  Dtype  \n",
      "---  ------                        --------------  -----  \n",
      " 0   Berichtsjahr                  21924 non-null  object \n",
      " 1   Berichtsmonat                 21924 non-null  object \n",
      " 2   Segment                       21924 non-null  object \n",
      " 3   Marke                         21924 non-null  object \n",
      " 4   Modellreihe                   21924 non-null  object \n",
      " 5   Anzahl                        21924 non-null  int64  \n",
      " 6   Diesel                        10280 non-null  float64\n",
      " 7   Hybrid                        10015 non-null  float64\n",
      " 8   Benzin-Hybrid                 9726 non-null   float64\n",
      " 9   Diesel-Hybrid                 3099 non-null   float64\n",
      " 10  Hybrid (ohne Plug-in)         7838 non-null   float64\n",
      " 11  Benzin-Hybrid (ohne Plug-in)  7339 non-null   float64\n",
      " 12  Diesel-Hybrid (ohne Plug-in)  3043 non-null   float64\n",
      " 13  Plug-in-Hybrid                5866 non-null   float64\n",
      " 14  Benzin-Plug-in-Hybrid         5858 non-null   float64\n",
      " 15  Diesel-Plug-in-Hybrid         289 non-null    float64\n",
      " 16  Elektro (BEV)                 5458 non-null   float64\n",
      " 17  Allradantrieb                 13301 non-null  float64\n",
      " 18  offener Aufbau                2039 non-null   float64\n",
      " 19  gewerblich                    21655 non-null  float64\n",
      " 20  ObjectId                      21924 non-null  int64  \n",
      "dtypes: float64(14), int64(2), object(5)\n",
      "memory usage: 3.5+ MB\n",
      "\n",
      "Ready.\n"
     ]
    }
   ],
   "source": [
    "DATA_DIR  = Path(\"../data/processed/,\")\n",
    "FILES     = [\"_handelsnamen_pkw.csv\", \"_modellreihen.csv\"]\n",
    "KEEP_TEXT = 5\n",
    "\n",
    "def _to_float(col: pd.Series) -> pd.Series:\n",
    "    dash_rx = re.compile(r\"^[-\\u2013\\u2014]$\")\n",
    "    col = col.str.strip()\n",
    "    col = col.mask(col.str.match(dash_rx) | (col == \".\"), pd.NA)\n",
    "    col = col.str.replace(r\"\\s|\\.\", \"\", regex=True)\n",
    "    col = col.str.replace(\",\", \".\", regex=False)\n",
    "    return pd.to_numeric(col, errors=\"coerce\")\n",
    "\n",
    "for fname in FILES:\n",
    "    path = DATA_DIR / fname\n",
    "    if not path.exists():\n",
    "        print(f\"!! {fname} not found\")\n",
    "        continue\n",
    "\n",
    "    df = pd.read_csv(path, dtype=str)\n",
    "    df.columns = df.columns.str.strip()\n",
    "\n",
    "    zs_mask = df.columns.str.contains(r\"ZS\\s|\\sZS\", case=False, regex=True)\n",
    "    if zs_mask.any():\n",
    "        df = df.loc[:, ~zs_mask]\n",
    "\n",
    "    numeric_cols = df.columns[KEEP_TEXT:]\n",
    "    for col in numeric_cols:\n",
    "        df[col] = _to_float(df[col])\n",
    "\n",
    "    df.to_csv(path, index=False, encoding=\"utf-8\")\n",
    "    df.info()\n",
    "\n",
    "print(\"\\nReady.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "45da5561",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = Path(\"../data/processed/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bed27a4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded: capstone_jan_artur.fz_1.2_raw\n",
      "Uploaded: capstone_jan_artur._handelsnamen_pkw\n",
      "Uploaded: capstone_jan_artur.fz_1.1_raw\n",
      "Uploaded: capstone_jan_artur.fz_08.7_raw\n",
      "Uploaded: capstone_jan_artur._modellreihen\n",
      "Uploaded: capstone_jan_artur.fz_2.4_raw\n",
      "Uploaded: capstone_jan_artur.fz_08.6_raw\n",
      "Uploaded: capstone_jan_artur.fz_08.3_raw\n",
      "Uploaded: capstone_jan_artur.fz_10.1_raw\n",
      "Uploaded: capstone_jan_artur.fz_08.2_raw\n",
      "Uploaded: capstone_jan_artur.fz_08.16_raw\n",
      "Uploaded: capstone_jan_artur.fz_3.1_raw\n",
      "Uploaded: capstone_jan_artur.fz_08.9_raw\n",
      "Uploaded: capstone_jan_artur.fz_2.2_raw\n",
      "Uploaded: capstone_jan_artur.fz_08.8_raw\n",
      "Uploaded: capstone_jan_artur._eu_recall_2025_06_09\n",
      "Uploaded: capstone_jan_artur._ladesaeulenregister_2025_05_07\n",
      "Uploaded: capstone_jan_artur._rueckruf_2025_06_09\n"
     ]
    }
   ],
   "source": [
    "# Walk both “;” and “,” subfolders\n",
    "for csv_path in data_dir.glob(\"*/*.csv\"):\n",
    "    # derive table name from filename\n",
    "    table_name = csv_path.stem.lower().replace(\"-\", \"_\")\n",
    "\n",
    "    # determine delimiter from the parent folder name\n",
    "    sep = csv_path.parent.name  # either \";\" or \",\"\n",
    "\n",
    "    # read CSV as text, with the correct delimiter\n",
    "    df = pd.read_csv(\n",
    "        csv_path,\n",
    "        # dtype=str,\n",
    "        sep=sep,\n",
    "        engine=\"python\",\n",
    "        on_bad_lines=\"warn\",\n",
    "        encoding=\"utf-8\"\n",
    "    )\n",
    "\n",
    "    # map every column to TEXT in Postgres\n",
    "    # dtype_dict = {col: Text() for col in df.columns}\n",
    "    \n",
    "    # write (replace) into the target schema\n",
    "    df.to_sql(\n",
    "        name      = table_name,\n",
    "        con       = engine,\n",
    "        schema    = pg_schema,\n",
    "        if_exists = \"replace\",\n",
    "        index     = False,\n",
    "        # dtype     = dtype_dict\n",
    "    )\n",
    "    \n",
    "    print(f\"Uploaded: {pg_schema}.{table_name}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
